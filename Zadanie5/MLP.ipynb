{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn terminal:\\n1. Open folder where you want to create the virtual environment\\n2. Run \"python3 -m venv env_name\" to create a virtual environment named \"env_name\"\\n3. Run \"source env_name/bin/activate\" to activate the virtual environment\\n\\nIn VSC:\\n1. Open Command Palette(Ctrl+Shift+P) and type \"Python: Select Interpreter\"\\n2. Select the python interpreter that you want to use\\n3. Select Kernel: Restart Kernel and Clear All Outputs\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In terminal:\n",
    "1. Open folder where you want to create the virtual environment\n",
    "2. Run \"python3 -m venv env_name\" to create a virtual environment named \"env_name\"\n",
    "3. Run \"source env_name/bin/activate\" to activate the virtual environment\n",
    "\n",
    "In VSC:\n",
    "1. Open Command Palette(Ctrl+Shift+P) and type \"Python: Select Interpreter\"\n",
    "2. Select the python interpreter that you want to use\n",
    "3. Select Kernel: Restart Kernel and Clear All Outputs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./zadanie5env/lib/python3.12/site-packages (24.0)\n",
      "Requirement already satisfied: numpy in ./zadanie5env/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in ./zadanie5env/lib/python3.12/site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./zadanie5env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./zadanie5env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in ./zadanie5env/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./zadanie5env/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./zadanie5env/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./zadanie5env/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./zadanie5env/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "## Instalowanie modułów\n",
    "\n",
    "!pip3 install --upgrade pip\n",
    "\n",
    "!pip3 install -U numpy\n",
    "!pip3 install -U matplotlib\n",
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importowanie modułów\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code from scikit-learn.org\n",
    "\n",
    "# digits = load_digits()\n",
    "# print(digits.data.shape)\n",
    "\n",
    "# plt.gray()\n",
    "# plt.matshow(digits.images[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Przygotowanie danych\n",
    "\n",
    "# Ładowanie danych\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Podział danych na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Konwersja etykiet na postać one-hot\n",
    "def one_hot_encode(y, num_classes):\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "y_train_one_hot = one_hot_encode(y_train, 10)\n",
    "y_test_one_hot = one_hot_encode(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funkcje aktywacji\n",
    "\n",
    "# ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Przejście do przodu\n",
    "\n",
    "def forward_propagation(X, parameters, activation_func):\n",
    "    cache = {'A0': X}\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        A_prev = cache['A' + str(l-1)]\n",
    "        \n",
    "        Z = np.dot(W, A_prev.T) + b\n",
    "        Z = Z.T\n",
    "        \n",
    "        if l == L:\n",
    "            A = sigmoid(Z)\n",
    "        else:\n",
    "            A = activation_func(Z)\n",
    "        \n",
    "        cache['Z' + str(l)] = Z\n",
    "        cache['A' + str(l)] = A\n",
    "    \n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Przejście do tyłu\n",
    "\n",
    "def backward_propagation(y, parameters, cache, activation_derivative):\n",
    "    grads = {}\n",
    "    L = len(parameters) // 2\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    dA = cache['A' + str(L)] - y\n",
    "    dZ = dA * sigmoid_derivative(cache['Z' + str(L)])\n",
    "    \n",
    "    for l in reversed(range(1, L+1)):\n",
    "        A_prev = cache['A' + str(l-1)] if l > 1 else cache['A0']\n",
    "        dW = np.dot(dZ.T, A_prev) / m\n",
    "        db = np.sum(dZ, axis=0, keepdims=True).T / m\n",
    "        \n",
    "        grads['dW' + str(l)] = dW\n",
    "        grads['db' + str(l)] = db\n",
    "        \n",
    "        if l > 1:\n",
    "            dA = np.dot(dZ, parameters['W' + str(l)])\n",
    "            dZ = dA * activation_derivative(cache['Z' + str(l-1)])\n",
    "    \n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SGD\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        parameters['W' + str(l)] -= learning_rate * grads['dW' + str(l)]\n",
    "        parameters['b' + str(l)] -= learning_rate * grads['db' + str(l)]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uczenie sieci\n",
    "\n",
    "def train(X, y, layer_dims, learning_rate=0.01, num_epochs=1000, batch_size=32, activation_func=relu, activation_derivative=relu_derivative):\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        \n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            y_pred, cache = forward_propagation(X_batch, parameters, activation_func)\n",
    "            grads = backward_propagation(y_batch, parameters, cache, activation_derivative)\n",
    "            parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            predictions = np.argmax(y_pred, axis=1)\n",
    "            labels = np.argmax(y_batch, axis=1)\n",
    "            accuracy = accuracy_score(labels, predictions)\n",
    "            f1 = f1_score(labels, predictions, average='micro')\n",
    "            print(f\"{activation_func}: Epoch {epoch} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (32,2048) and (64,32) not aligned: 2048 (dim 1) != 64 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Trenowanie sieci\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m parameters_relu \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_derivative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelu_derivative\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m parameters_sigmoid \u001b[38;5;241m=\u001b[39m train(X_train, y_train_one_hot, layer_dims, learning_rate, num_epochs, batch_size, activation_func\u001b[38;5;241m=\u001b[39msigmoid, activation_derivative\u001b[38;5;241m=\u001b[39msigmoid_derivative)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Ewaluacja na zbiorze testowym\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(X, y, layer_dims, learning_rate, num_epochs, batch_size, activation_func, activation_derivative)\u001b[0m\n\u001b[1;32m     13\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_shuffled[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m     14\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m y_shuffled[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 16\u001b[0m y_pred, cache \u001b[38;5;241m=\u001b[39m \u001b[43mforward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m grads \u001b[38;5;241m=\u001b[39m backward_propagation(y_batch, parameters, cache, activation_derivative)\n\u001b[1;32m     18\u001b[0m parameters \u001b[38;5;241m=\u001b[39m update_parameters(parameters, grads, learning_rate)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mforward_propagation\u001b[0;34m(X, parameters, activation_func)\u001b[0m\n\u001b[1;32m      9\u001b[0m b \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l)]\n\u001b[1;32m     10\u001b[0m A_prev \u001b[38;5;241m=\u001b[39m cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m---> 12\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_prev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n\u001b[1;32m     13\u001b[0m Z \u001b[38;5;241m=\u001b[39m Z\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l \u001b[38;5;241m==\u001b[39m L:\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (32,2048) and (64,32) not aligned: 2048 (dim 1) != 64 (dim 0)"
     ]
    }
   ],
   "source": [
    "## Ewaluacja sieci\n",
    "\n",
    "def evaluate(X, y, parameters, activation_func):\n",
    "    y_pred, _ = forward_propagation(X, parameters, activation_func)\n",
    "    predictions = np.argmax(y_pred, axis=1)\n",
    "    labels = np.argmax(y, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='micro')\n",
    "    return accuracy, f1\n",
    "\n",
    "# Parametry sieci\n",
    "layer_dims = [64, 32, 16, 10]\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# Trenowanie sieci\n",
    "parameters_relu = train(X_train, y_train_one_hot, layer_dims, learning_rate, num_epochs, batch_size, activation_func=relu, activation_derivative=relu_derivative)\n",
    "parameters_sigmoid = train(X_train, y_train_one_hot, layer_dims, learning_rate, num_epochs, batch_size, activation_func=sigmoid, activation_derivative=sigmoid_derivative)\n",
    "\n",
    "# Ewaluacja na zbiorze testowym\n",
    "accuracy, f1 = evaluate(X_test, y_test_one_hot, parameters_relu, relu)\n",
    "print(f\"ReLU: Test Accuracy: {accuracy:.4f}, Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "accuracy, f1 = evaluate(X_test, y_test_one_hot, parameters_sigmoid, sigmoid)\n",
    "print(f\"Sigmoid: Test Accuracy: {accuracy:.4f}, Test F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zadanie5env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
