{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In terminal:\n",
    "1. Open folder where you want to create the virtual environment\n",
    "2. Run \"python3 -m venv env_name\" to create a virtual environment named \"env_name\"\n",
    "3. Run \"source env_name/bin/activate\" to activate the virtual environment\n",
    "\n",
    "In VSC:\n",
    "1. Open Command Palette(Ctrl+Shift+P) and type \"Python: Select Interpreter\"\n",
    "2. Select the python interpreter that you want to use\n",
    "3. Select Kernel: Restart Kernel and Clear All Outputs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instalowanie modułów\n",
    "\n",
    "!pip3 install --upgrade pip\n",
    "\n",
    "!pip3 install -U numpy\n",
    "!pip3 install -U matplotlib\n",
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importowanie modułów\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code from scikit-learn.org\n",
    "\n",
    "# digits = load_digits()\n",
    "# print(digits.data.shape)\n",
    "\n",
    "# plt.gray()\n",
    "# plt.matshow(digits.images[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Przygotowanie danych\n",
    "\n",
    "# Ładowanie danych\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Podział danych na zbiory treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Konwersja etykiet na postać one-hot\n",
    "def one_hot_encode(y, num_classes):\n",
    "    one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    one_hot[np.arange(y.shape[0]), y] = 1\n",
    "    return one_hot\n",
    "\n",
    "y_train_one_hot = one_hot_encode(y_train, 10)\n",
    "y_test_one_hot = one_hot_encode(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funkcje aktywacji\n",
    "\n",
    "# ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# Sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Przejście do przodu\n",
    "\n",
    "def forward_propagation(X, parameters, activation_func):\n",
    "    cache = {'A0': X}\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        A_prev = cache['A' + str(l-1)]\n",
    "        \n",
    "        Z = np.dot(W, A_prev.T) + b\n",
    "        Z = Z.T\n",
    "        \n",
    "        if l == L:\n",
    "            A = sigmoid(Z)\n",
    "        else:\n",
    "            A = activation_func(Z)\n",
    "        \n",
    "        cache['Z' + str(l)] = Z\n",
    "        cache['A' + str(l)] = A\n",
    "    \n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Przejście do tyłu\n",
    "\n",
    "def backward_propagation(y, parameters, cache, activation_derivative):\n",
    "    grads = {}\n",
    "    L = len(parameters) // 2\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    dA = cache['A' + str(L)] - y\n",
    "    dZ = dA * sigmoid_derivative(cache['Z' + str(L)])\n",
    "    \n",
    "    for l in reversed(range(1, L+1)):\n",
    "        A_prev = cache['A' + str(l-1)] if l > 1 else cache['A0']\n",
    "        dW = np.dot(dZ.T, A_prev) / m\n",
    "        db = np.sum(dZ, axis=0, keepdims=True).T / m\n",
    "        \n",
    "        grads['dW' + str(l)] = dW\n",
    "        grads['db' + str(l)] = db\n",
    "        \n",
    "        if l > 1:\n",
    "            dA = np.dot(dZ, parameters['W' + str(l)])\n",
    "            dZ = dA * activation_derivative(cache['Z' + str(l-1)])\n",
    "    \n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SGD\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        parameters['W' + str(l)] -= learning_rate * grads['dW' + str(l)]\n",
    "        parameters['b' + str(l)] -= learning_rate * grads['db' + str(l)]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uczenie sieci\n",
    "\n",
    "def train(X, y, layer_dims, learning_rate=0.01, num_epochs=1000, batch_size=32, activation_func=relu, activation_derivative=relu_derivative):\n",
    "    parameters = initialize_parameters(layer_dims)\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        shuffled_indices = np.random.permutation(m)\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        y_shuffled = y[shuffled_indices]\n",
    "        \n",
    "        for i in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "            \n",
    "            y_pred, cache = forward_propagation(X_batch, parameters, activation_func)\n",
    "            grads = backward_propagation(y_batch, parameters, cache, activation_derivative)\n",
    "            parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            predictions = np.argmax(y_pred, axis=1)\n",
    "            labels = np.argmax(y_batch, axis=1)\n",
    "            accuracy = accuracy_score(labels, predictions)\n",
    "            f1 = f1_score(labels, predictions, average='micro')\n",
    "            print(f\"Epoch {epoch} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Accuracy: 0.1111, F1 Score: 0.1111\n",
      "Epoch 100 - Accuracy: 0.3333, F1 Score: 0.3333\n",
      "Epoch 200 - Accuracy: 0.0000, F1 Score: 0.0000\n",
      "Epoch 300 - Accuracy: 0.2222, F1 Score: 0.2222\n",
      "Epoch 400 - Accuracy: 0.1111, F1 Score: 0.1111\n",
      "Epoch 500 - Accuracy: 0.3333, F1 Score: 0.3333\n",
      "Epoch 600 - Accuracy: 0.3333, F1 Score: 0.3333\n",
      "Epoch 700 - Accuracy: 0.0000, F1 Score: 0.0000\n",
      "Epoch 800 - Accuracy: 0.1111, F1 Score: 0.1111\n",
      "Epoch 900 - Accuracy: 0.3333, F1 Score: 0.3333\n",
      "Test Accuracy: 0.1963, Test F1 Score: 0.1963\n"
     ]
    }
   ],
   "source": [
    "## Ewaluacja sieci\n",
    "\n",
    "def evaluate(X, y, parameters, activation_func):\n",
    "    y_pred, _ = forward_propagation(X, parameters, activation_func)\n",
    "    predictions = np.argmax(y_pred, axis=1)\n",
    "    labels = np.argmax(y, axis=1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='micro')\n",
    "    return accuracy, f1\n",
    "\n",
    "# Parametry sieci\n",
    "layer_dims = [64, 32, 16, 10]\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# Trenowanie sieci\n",
    "parameters = train(X_train, y_train_one_hot, layer_dims, learning_rate, num_epochs, batch_size, activation_func=relu, activation_derivative=relu_derivative)\n",
    "\n",
    "# Ewaluacja na zbiorze testowym\n",
    "accuracy, f1 = evaluate(X_test, y_test_one_hot, parameters, relu)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}, Test F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zadanie5env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
